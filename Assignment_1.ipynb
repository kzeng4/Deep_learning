{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kzeng4/Deep_learning/blob/Logistic-Regression/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAXWl83f2z9W"
      },
      "source": [
        "# HM1: Logistic Regression.\n",
        "\n",
        "### Name: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYgi5FE72z9Z"
      },
      "source": [
        "#### For this assignment, you will build 6 models. You need to train Logistic Regression/Regularized Logistic Regression each with Batch Gradient Descent, Stochastic Gradient Descent and Mini Batch Gradient Descent. Also you should plot their objective values versus epochs and compare their training and testing accuracies. You will need to tune the parameters a little bit to obtain reasonable results.\n",
        "\n",
        "#### You do not have to follow the following procedure. You may implement your own functions and methods, but you need to show your results and plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSAMFdjL2z9a"
      },
      "outputs": [],
      "source": [
        "# Load Packages\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujBBO3eN2z9b"
      },
      "source": [
        "# 1. Data processing\n",
        "\n",
        "- Download the Breast Cancer dataset from canvas or from https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
        "- Load the data.\n",
        "- Preprocess the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw1I_xvn2z9c"
      },
      "source": [
        "## 1.1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgVdCpsg2z9c",
        "outputId": "e228f21f-e245-4c25-9c5c-0da03b7853e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 1149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd-2ICj-2z9d"
      },
      "source": [
        "## 1.2 Examine and clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0L0J-g-2z9e",
        "outputId": "f71beb0d-874a-4446-b1bc-0e28bf2f2928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0           -1        17.99         10.38          122.80     1001.0   \n",
            "1           -1        20.57         17.77          132.90     1326.0   \n",
            "2           -1        19.69         21.25          130.00     1203.0   \n",
            "3           -1        11.42         20.38           77.58      386.1   \n",
            "4           -1        20.29         14.34          135.10     1297.0   \n",
            "..         ...          ...           ...             ...        ...   \n",
            "564         -1        21.56         22.39          142.00     1479.0   \n",
            "565         -1        20.13         28.25          131.20     1261.0   \n",
            "566         -1        16.60         28.08          108.30      858.1   \n",
            "567         -1        20.60         29.33          140.10     1265.0   \n",
            "568          1         7.76         24.54           47.92      181.0   \n",
            "\n",
            "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0            0.11840           0.27760         0.30010              0.14710   \n",
            "1            0.08474           0.07864         0.08690              0.07017   \n",
            "2            0.10960           0.15990         0.19740              0.12790   \n",
            "3            0.14250           0.28390         0.24140              0.10520   \n",
            "4            0.10030           0.13280         0.19800              0.10430   \n",
            "..               ...               ...             ...                  ...   \n",
            "564          0.11100           0.11590         0.24390              0.13890   \n",
            "565          0.09780           0.10340         0.14400              0.09791   \n",
            "566          0.08455           0.10230         0.09251              0.05302   \n",
            "567          0.11780           0.27700         0.35140              0.15200   \n",
            "568          0.05263           0.04362         0.00000              0.00000   \n",
            "\n",
            "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0           0.2419  ...        25.380          17.33           184.60   \n",
            "1           0.1812  ...        24.990          23.41           158.80   \n",
            "2           0.2069  ...        23.570          25.53           152.50   \n",
            "3           0.2597  ...        14.910          26.50            98.87   \n",
            "4           0.1809  ...        22.540          16.67           152.20   \n",
            "..             ...  ...           ...            ...              ...   \n",
            "564         0.1726  ...        25.450          26.40           166.10   \n",
            "565         0.1752  ...        23.690          38.25           155.00   \n",
            "566         0.1590  ...        18.980          34.12           126.70   \n",
            "567         0.2397  ...        25.740          39.42           184.60   \n",
            "568         0.1587  ...         9.456          30.37            59.16   \n",
            "\n",
            "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0        2019.0           0.16220            0.66560           0.7119   \n",
            "1        1956.0           0.12380            0.18660           0.2416   \n",
            "2        1709.0           0.14440            0.42450           0.4504   \n",
            "3         567.7           0.20980            0.86630           0.6869   \n",
            "4        1575.0           0.13740            0.20500           0.4000   \n",
            "..          ...               ...                ...              ...   \n",
            "564      2027.0           0.14100            0.21130           0.4107   \n",
            "565      1731.0           0.11660            0.19220           0.3215   \n",
            "566      1124.0           0.11390            0.30940           0.3403   \n",
            "567      1821.0           0.16500            0.86810           0.9387   \n",
            "568       268.6           0.08996            0.06444           0.0000   \n",
            "\n",
            "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "0                  0.2654          0.4601                  0.11890  \n",
            "1                  0.1860          0.2750                  0.08902  \n",
            "2                  0.2430          0.3613                  0.08758  \n",
            "3                  0.2575          0.6638                  0.17300  \n",
            "4                  0.1625          0.2364                  0.07678  \n",
            "..                    ...             ...                      ...  \n",
            "564                0.2216          0.2060                  0.07115  \n",
            "565                0.1628          0.2572                  0.06637  \n",
            "566                0.1418          0.2218                  0.07820  \n",
            "567                0.2650          0.4087                  0.12400  \n",
            "568                0.0000          0.2871                  0.07039  \n",
            "\n",
            "[569 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "# Some columns may not be useful for the model (For example, the first column contains ID number which may be irrelavant). \n",
        "# You need to get rid of the ID number feature.\n",
        "# Also you should transform target labels in the second column from 'B' and 'M' to 1 and -1.\n",
        "\n",
        "\n",
        "data=data.drop(['id','Unnamed: 32'],axis=1).replace({'diagnosis':{'M':-1,'B':1}})\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNiET1uR2z9e"
      },
      "source": [
        "## 1.3. Partition to training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25TWPorx2z9f"
      },
      "outputs": [],
      "source": [
        "# You can partition using 80% training data and 20% testing data. It is a commonly used ratio in machinel learning.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.drop(['diagnosis'],axis=1),data['diagnosis'],test_size=0.2,random_state=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8afYIOmF2z9f",
        "outputId": "6ab8ca89-ee53-4693-ebf4-60c5092886cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>10.26</td>\n",
              "      <td>14.71</td>\n",
              "      <td>66.20</td>\n",
              "      <td>321.6</td>\n",
              "      <td>0.09882</td>\n",
              "      <td>0.09159</td>\n",
              "      <td>0.03581</td>\n",
              "      <td>0.02037</td>\n",
              "      <td>0.1633</td>\n",
              "      <td>0.07005</td>\n",
              "      <td>...</td>\n",
              "      <td>10.88</td>\n",
              "      <td>19.48</td>\n",
              "      <td>70.89</td>\n",
              "      <td>357.1</td>\n",
              "      <td>0.1360</td>\n",
              "      <td>0.1636</td>\n",
              "      <td>0.07162</td>\n",
              "      <td>0.04074</td>\n",
              "      <td>0.2434</td>\n",
              "      <td>0.08488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>12.36</td>\n",
              "      <td>18.54</td>\n",
              "      <td>79.01</td>\n",
              "      <td>466.7</td>\n",
              "      <td>0.08477</td>\n",
              "      <td>0.06815</td>\n",
              "      <td>0.02643</td>\n",
              "      <td>0.01921</td>\n",
              "      <td>0.1602</td>\n",
              "      <td>0.06066</td>\n",
              "      <td>...</td>\n",
              "      <td>13.29</td>\n",
              "      <td>27.49</td>\n",
              "      <td>85.56</td>\n",
              "      <td>544.1</td>\n",
              "      <td>0.1184</td>\n",
              "      <td>0.1963</td>\n",
              "      <td>0.19370</td>\n",
              "      <td>0.08442</td>\n",
              "      <td>0.2983</td>\n",
              "      <td>0.07185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>14.68</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>0.1586</td>\n",
              "      <td>0.05922</td>\n",
              "      <td>...</td>\n",
              "      <td>19.07</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.29140</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>13.30</td>\n",
              "      <td>21.57</td>\n",
              "      <td>85.24</td>\n",
              "      <td>546.1</td>\n",
              "      <td>0.08582</td>\n",
              "      <td>0.06373</td>\n",
              "      <td>0.03344</td>\n",
              "      <td>0.02424</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.05696</td>\n",
              "      <td>...</td>\n",
              "      <td>14.20</td>\n",
              "      <td>29.20</td>\n",
              "      <td>92.94</td>\n",
              "      <td>621.2</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.12120</td>\n",
              "      <td>0.05614</td>\n",
              "      <td>0.2637</td>\n",
              "      <td>0.06658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>15.08</td>\n",
              "      <td>25.74</td>\n",
              "      <td>98.00</td>\n",
              "      <td>716.6</td>\n",
              "      <td>0.10240</td>\n",
              "      <td>0.09769</td>\n",
              "      <td>0.12350</td>\n",
              "      <td>0.06553</td>\n",
              "      <td>0.1647</td>\n",
              "      <td>0.06464</td>\n",
              "      <td>...</td>\n",
              "      <td>18.51</td>\n",
              "      <td>33.22</td>\n",
              "      <td>121.20</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0.1660</td>\n",
              "      <td>0.2356</td>\n",
              "      <td>0.40290</td>\n",
              "      <td>0.15260</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.09438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "345        10.26         14.71           66.20      321.6          0.09882   \n",
              "107        12.36         18.54           79.01      466.7          0.08477   \n",
              "16         14.68         20.13           94.74      684.5          0.09867   \n",
              "361        13.30         21.57           85.24      546.1          0.08582   \n",
              "353        15.08         25.74           98.00      716.6          0.10240   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "345           0.09159         0.03581              0.02037         0.1633   \n",
              "107           0.06815         0.02643              0.01921         0.1602   \n",
              "16            0.07200         0.07395              0.05259         0.1586   \n",
              "361           0.06373         0.03344              0.02424         0.1815   \n",
              "353           0.09769         0.12350              0.06553         0.1647   \n",
              "\n",
              "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
              "345                 0.07005  ...         10.88          19.48   \n",
              "107                 0.06066  ...         13.29          27.49   \n",
              "16                  0.05922  ...         19.07          30.88   \n",
              "361                 0.05696  ...         14.20          29.20   \n",
              "353                 0.06464  ...         18.51          33.22   \n",
              "\n",
              "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "345            70.89       357.1            0.1360             0.1636   \n",
              "107            85.56       544.1            0.1184             0.1963   \n",
              "16            123.40      1138.0            0.1464             0.1871   \n",
              "361            92.94       621.2            0.1140             0.1667   \n",
              "353           121.20      1050.0            0.1660             0.2356   \n",
              "\n",
              "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "345          0.07162               0.04074          0.2434   \n",
              "107          0.19370               0.08442          0.2983   \n",
              "16           0.29140               0.16090          0.3029   \n",
              "361          0.12120               0.05614          0.2637   \n",
              "353          0.40290               0.15260          0.2654   \n",
              "\n",
              "     fractal_dimension_worst  \n",
              "345                  0.08488  \n",
              "107                  0.07185  \n",
              "16                   0.08216  \n",
              "361                  0.06658  \n",
              "353                  0.09438  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 1153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITrxWhji2z9g",
        "outputId": "a359a04e-ad0d-412a-fe43-7c343a4b6448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(455,)"
            ]
          },
          "execution_count": 1155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCYQ9EAj2z9g"
      },
      "source": [
        "## 1.4. Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00izDN572z9h"
      },
      "source": [
        "Use the standardization to trainsform both training and test features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRrm8Kdl2z9h",
        "outputId": "4cea974a-0e4b-440b-85c7-016fbcf61bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test mean = \n",
            "radius_mean               -0.016452\n",
            "texture_mean              -0.006475\n",
            "perimeter_mean            -0.010339\n",
            "area_mean                 -0.026655\n",
            "smoothness_mean            0.058614\n",
            "compactness_mean           0.056717\n",
            "concavity_mean            -0.006780\n",
            "concave points_mean        0.012189\n",
            "symmetry_mean              0.117378\n",
            "fractal_dimension_mean     0.022540\n",
            "radius_se                  0.029754\n",
            "texture_se                -0.072045\n",
            "perimeter_se               0.057842\n",
            "area_se                   -0.020637\n",
            "smoothness_se             -0.020818\n",
            "compactness_se            -0.006127\n",
            "concavity_se              -0.007867\n",
            "concave points_se          0.034431\n",
            "symmetry_se                0.048284\n",
            "fractal_dimension_se      -0.035465\n",
            "radius_worst              -0.007602\n",
            "texture_worst             -0.088374\n",
            "perimeter_worst            0.001201\n",
            "area_worst                -0.010722\n",
            "smoothness_worst          -0.008194\n",
            "compactness_worst          0.005816\n",
            "concavity_worst           -0.020306\n",
            "concave points_worst      -0.003757\n",
            "symmetry_worst             0.017610\n",
            "fractal_dimension_worst   -0.020143\n",
            "dtype: float64\n",
            "test std = \n",
            "radius_mean                0.939804\n",
            "texture_mean               0.912604\n",
            "perimeter_mean             0.936371\n",
            "area_mean                  0.899978\n",
            "smoothness_mean            0.923458\n",
            "compactness_mean           0.900743\n",
            "concavity_mean             0.900221\n",
            "concave points_mean        0.894339\n",
            "symmetry_mean              0.882758\n",
            "fractal_dimension_mean     0.843833\n",
            "radius_se                  0.869058\n",
            "texture_se                 0.866246\n",
            "perimeter_se               0.833523\n",
            "area_se                    0.731393\n",
            "smoothness_se              0.815537\n",
            "compactness_se             0.868964\n",
            "concavity_se               0.759362\n",
            "concave points_se          0.844337\n",
            "symmetry_se                0.866818\n",
            "fractal_dimension_se       0.728252\n",
            "radius_worst               0.969669\n",
            "texture_worst              0.877052\n",
            "perimeter_worst            0.963067\n",
            "area_worst                 0.973403\n",
            "smoothness_worst           0.901366\n",
            "compactness_worst          0.913739\n",
            "concavity_worst            0.906853\n",
            "concave points_worst       0.931123\n",
            "symmetry_worst             0.930784\n",
            "fractal_dimension_worst    0.903583\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Standardization\n",
        "import numpy\n",
        "\n",
        "# calculate mu and sig using the training set\n",
        "d = x_train.shape[1]\n",
        "mu = numpy.mean(x_train, axis=0).values.reshape(1, d)\n",
        "sig = numpy.std(x_train, axis=0).values.reshape(1, d)\n",
        "\n",
        "# transform the training features\n",
        "x_train = (x_train - mu) / (sig + 1E-6)\n",
        "\n",
        "# transform the test features\n",
        "x_test = (x_test - mu) / (sig + 1E-6)\n",
        "\n",
        "print('test mean = ')\n",
        "print(numpy.mean(x_test, axis=0))\n",
        "\n",
        "print('test std = ')\n",
        "print(numpy.std(x_test, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM7Kiwc02z9h",
        "outputId": "5b7de972-c328-438a-a3e7-7dfc85ffff38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.41390352e+01, 1.92953187e+01, 9.20199560e+01, 6.56803516e+02,\n",
              "        9.61928132e-02, 1.03729868e-01, 8.89096330e-02, 4.88225099e-02,\n",
              "        1.80503736e-01, 6.27647912e-02, 4.03478462e-01, 1.22501231e+00,\n",
              "        2.84190549e+00, 4.05344154e+01, 7.05393626e-03, 2.55006615e-02,\n",
              "        3.19434086e-02, 1.17523297e-02, 2.04603429e-02, 3.81464462e-03,\n",
              "        1.62765890e+01, 2.57884835e+01, 1.07253077e+02, 8.81811648e+02,\n",
              "        1.32406769e-01, 2.54078769e-01, 2.73051976e-01, 1.14656332e-01,\n",
              "        2.89854505e-01, 8.40200220e-02]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "d = x_train.shape[1]\n",
        "numpy.mean(x_train, axis=0).values.reshape(1, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSiD4IUh2z9i"
      },
      "source": [
        "# 2.  Logistic Regression Model\n",
        "\n",
        "The objective function is $Q (w; X, y) = \\frac{1}{n} \\sum_{i=1}^n \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $.\n",
        "\n",
        "When $\\lambda = 0$, the model is a regular logistric regression and when $\\lambda > 0$, it essentially becomes a regularized logistric regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKqzIJzD2z9i"
      },
      "outputs": [],
      "source": [
        "# Calculate the objective function value, or loss\n",
        "# Inputs:\n",
        "#     w: weight: d-by-1 matrix\n",
        "#     x: data: n-by-d matrix\n",
        "#     y: label: n-by-1 matrix\n",
        "#     lam: regularization parameter: scalar\n",
        "# Return:\n",
        "#     objective function value, or loss (scalar)\n",
        "#clf = LogisticRegression(random_state=0).fit(x_train, y_train)\n",
        "\n",
        "def objective(w, x, y, lam):\n",
        "    \n",
        "    \n",
        "    n = x.shape[0]\n",
        "    yx = numpy.multiply(y, x) #n-by-d\n",
        "    yxw = numpy.dot(yx, w)#n-by-1\n",
        "    vec = numpy.log(1+numpy.exp(-yxw))  #n-by-1\n",
        "    reg = lam/2*(norm(w)**2) #scalar\n",
        "    Q = numpy.mean(vec)+reg #scalar\n",
        "    return Q\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_y76_8U2z9j"
      },
      "source": [
        "# 3. Numerical optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhzP-z4Q2z9j"
      },
      "source": [
        "## 3.1. Gradient descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06c4N7-A2z9j"
      },
      "source": [
        "The gradient at $w$ for regularized logistic regression is  $g = - \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu8rrps22z9j"
      },
      "outputs": [],
      "source": [
        "# Calculate the gradient\n",
        "# Inputs:\n",
        "#     w: weight: d-by-1 matrix\n",
        "#     x: data: n-by-d matrix\n",
        "#     y: label: n-by-1 matrix\n",
        "#     lam: regularization parameter: scalar\n",
        "# Return:\n",
        "#     g: gradient: d-by-1 matrix\n",
        "\n",
        "def gradient(w, x, y, lam):\n",
        "    \n",
        "    n,d = x.shape\n",
        "    yx = numpy.multiply(y, x) #n-by-d\n",
        "    yxw = numpy.dot(yx, w)#n-by-1\n",
        "    vec = numpy.divide(yx,1+numpy.exp(yxw))   #n-by-d\n",
        "    reg = lam * w  #d-by-1\n",
        "    gradient = -numpy.mean(vec,axis=0).reshape(d,1)+reg\n",
        "    return gradient\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7xeGSk32z9k"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_train = y_train.reshape(455,1)\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2_vDOnb2z9k"
      },
      "outputs": [],
      "source": [
        "# Gradient descent for solving logistic regression\n",
        "# You will need to do iterative process (loops) to obtain optimal weights in this function\n",
        "\n",
        "# Inputs:\n",
        "#     x: data: n-by-d matrix\n",
        "#     y: label: n-by-1 matrix\n",
        "#     lam: scalar, the regularization parameter\n",
        "#     learning_rate: scalar\n",
        "#     w: weights: d-by-1 matrix, initialization of w\n",
        "#     max_epoch: integer, the maximal epochs\n",
        "# Return:\n",
        "#     w: weights: d-by-1 matrix, the solution\n",
        "#     objvals: a record of each epoch's objective value\n",
        "\n",
        "def gradient_descent(x, y, lam, learning_rate, w=None, max_epoch=100):\n",
        "    w=numpy.zeros((x.shape[1],1))\n",
        "    objevals=[]\n",
        "    for j in range(max_epoch):\n",
        "        w -= learning_rate*gradient(w,x,y,lam)\n",
        "        \n",
        "        cost = objective(w, x, y, lam)\n",
        "        objevals.append(cost)\n",
        "        print(\"each epoch's objective value is\" + str(cost))\n",
        "    return w,objevals\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qE6SHLy2z9k"
      },
      "source": [
        "Use gradient_descent function to obtain your optimal weights and a list of objective values over each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFklEETQ2z9k",
        "outputId": "b547bbbe-c7c1-4471-e8d4-b82b9113b1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is0.5240065439423484\n",
            "each epoch's objective value is0.43817830196882684\n",
            "each epoch's objective value is0.38561143670246156\n",
            "each epoch's objective value is0.34936630759665727\n",
            "each epoch's objective value is0.3224695279113672\n",
            "each epoch's objective value is0.30149362758380077\n",
            "each epoch's objective value is0.28454000598407203\n",
            "each epoch's objective value is0.2704639386495843\n",
            "each epoch's objective value is0.25853011111153934\n",
            "each epoch's objective value is0.2482423371272637\n",
            "each epoch's objective value is0.2392522933649964\n",
            "each epoch's objective value is0.23130738629794986\n",
            "each epoch's objective value is0.22421939481896852\n",
            "each epoch's objective value is0.21784478543352467\n",
            "each epoch's objective value is0.21207190169959186\n",
            "each epoch's objective value is0.20681236655845975\n",
            "each epoch's objective value is0.20199515626464398\n",
            "each epoch's objective value is0.19756241946965886\n",
            "each epoch's objective value is0.19346646626253\n",
            "each epoch's objective value is0.18966755973867425\n",
            "each epoch's objective value is0.18613226939687053\n",
            "each epoch's objective value is0.18283222509888758\n",
            "each epoch's objective value is0.17974316134767737\n",
            "each epoch's objective value is0.1768441751394024\n",
            "each epoch's objective value is0.17411714308074902\n",
            "each epoch's objective value is0.17154625876283008\n",
            "each epoch's objective value is0.16911766198874761\n",
            "each epoch's objective value is0.16681913891438516\n",
            "each epoch's objective value is0.16463987748498268\n",
            "each epoch's objective value is0.1625702663947503\n",
            "each epoch's objective value is0.16060172860592556\n",
            "each epoch's objective value is0.1587265825382074\n",
            "each epoch's objective value is0.1569379255868016\n",
            "each epoch's objective value is0.15522953579216256\n",
            "each epoch's objective value is0.15359578836916918\n",
            "each epoch's objective value is0.15203158448094073\n",
            "each epoch's objective value is0.1505322901654311\n",
            "each epoch's objective value is0.1490936837296679\n",
            "each epoch's objective value is0.14771191024515767\n",
            "each epoch's objective value is0.14638344202939294\n",
            "each epoch's objective value is0.14510504419809617\n",
            "each epoch's objective value is0.14387374453249616\n",
            "each epoch's objective value is0.14268680703437528\n",
            "each epoch's objective value is0.1415417086455786\n",
            "each epoch's objective value is0.14043611869328979\n",
            "each epoch's objective value is0.13936788069163153\n",
            "each epoch's objective value is0.13833499618712494\n",
            "each epoch's objective value is0.1373356103826542\n",
            "each epoch's objective value is0.13636799931372284\n",
            "each epoch's objective value is0.13543055838345178\n",
            "each epoch's objective value is0.1345217920901457\n",
            "each epoch's objective value is0.13364030480429276\n",
            "each epoch's objective value is0.13278479247132427\n",
            "each epoch's objective value is0.13195403513296394\n",
            "each epoch's objective value is0.13114689017403472\n",
            "each epoch's objective value is0.13036228621357845\n",
            "each epoch's objective value is0.12959921756940415\n",
            "each epoch's objective value is0.12885673923399818\n",
            "each epoch's objective value is0.1281339623073196\n",
            "each epoch's objective value is0.1274300498385626\n",
            "each epoch's objective value is0.12674421303464395\n",
            "each epoch's objective value is0.12607570779810445\n",
            "each epoch's objective value is0.12542383156139872\n",
            "each epoch's objective value is0.12478792038828938\n",
            "each epoch's objective value is0.12416734631632939\n",
            "each epoch's objective value is0.1235615149172787\n",
            "each epoch's objective value is0.12296986305481405\n",
            "each epoch's objective value is0.12239185682109913\n",
            "each epoch's objective value is0.12182698963572895\n",
            "each epoch's objective value is0.12127478049227908\n",
            "each epoch's objective value is0.12073477233920958\n",
            "each epoch's objective value is0.120206530583218\n",
            "each epoch's objective value is0.11968964170432847\n",
            "each epoch's objective value is0.11918371197306438\n",
            "each epoch's objective value is0.11868836626099583\n",
            "each epoch's objective value is0.11820324693679217\n",
            "each epoch's objective value is0.1177280128406625\n",
            "each epoch's objective value is0.11726233833073627\n",
            "each epoch's objective value is0.11680591239553688\n",
            "each epoch's objective value is0.11635843782723962\n",
            "each epoch's objective value is0.11591963045088831\n",
            "each epoch's objective value is0.11548921840517833\n",
            "each epoch's objective value is0.11506694147080537\n",
            "each epoch's objective value is0.11465255044273044\n",
            "each epoch's objective value is0.11424580654302903\n",
            "each epoch's objective value is0.11384648087127952\n",
            "each epoch's objective value is0.11345435388970437\n",
            "each epoch's objective value is0.1130692149405127\n",
            "each epoch's objective value is0.11269086179310528\n",
            "each epoch's objective value is0.11231910021899569\n",
            "each epoch's objective value is0.11195374359247638\n",
            "each epoch's objective value is0.11159461251521781\n",
            "each epoch's objective value is0.11124153446313335\n",
            "each epoch's objective value is0.11089434345397482\n",
            "each epoch's objective value is0.11055287973424327\n",
            "each epoch's objective value is0.11021698948411006\n",
            "each epoch's objective value is0.10988652453914294\n",
            "each epoch's objective value is0.10956134212772362\n",
            "each epoch's objective value is0.1092413046231274\n",
            "each epoch's objective value is0.10892627930931194\n"
          ]
        }
      ],
      "source": [
        "# Train logistic regression\n",
        "# You should get the optimal weights and a list of objective values by using gradient_descent function.\n",
        "lam=1E-6\n",
        "w_optimal,loss=gradient_descent(x_train,y_train,0,0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn-QOjM-2z9k",
        "outputId": "57d2ba6c-2dff-47fd-c76f-6555597f8b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is0.5240075477182539\n",
            "each epoch's objective value is0.4381822614709369\n",
            "each epoch's objective value is0.3856186260921692\n",
            "each epoch's objective value is0.3493767053553161\n",
            "each epoch's objective value is0.3224830458964865\n",
            "each epoch's objective value is0.30151016493401545\n",
            "each epoch's objective value is0.2845594644214405\n",
            "each epoch's objective value is0.27048622678326445\n",
            "each epoch's objective value is0.25855514519331174\n",
            "each epoch's objective value is0.24827004063207897\n",
            "each epoch's objective value is0.23928259622698173\n",
            "each epoch's objective value is0.2313402241037832\n",
            "each epoch's objective value is0.22425470806501438\n",
            "each epoch's objective value is0.2178825188777189\n",
            "each epoch's objective value is0.21211200380988943\n",
            "each epoch's objective value is0.20685478904902366\n",
            "each epoch's objective value is0.20203985370788433\n",
            "each epoch's objective value is0.1976093489722009\n",
            "each epoch's objective value is0.19351558719429462\n",
            "each epoch's objective value is0.18971883350569746\n",
            "each epoch's objective value is0.18618565924993238\n",
            "each epoch's objective value is0.18288769597134347\n",
            "each epoch's objective value is0.17980067971704708\n",
            "each epoch's objective value is0.1769037089082666\n",
            "each epoch's objective value is0.17417866147334524\n",
            "each epoch's objective value is0.1716097322344411\n",
            "each epoch's objective value is0.16918306214555612\n",
            "each epoch's objective value is0.16688643844194098\n",
            "each epoch's objective value is0.1647090500838131\n",
            "each epoch's objective value is0.16264128672195066\n",
            "each epoch's objective value is0.16067457222181006\n",
            "each epoch's objective value is0.15880122585729317\n",
            "each epoch's objective value is0.1570143458325467\n",
            "each epoch's objective value is0.1553077109549962\n",
            "each epoch's objective value is0.15367569716744084\n",
            "each epoch's objective value is0.15211320632448339\n",
            "each epoch's objective value is0.1506156051214876\n",
            "each epoch's objective value is0.14917867249096883\n",
            "each epoch's objective value is0.14779855409997109\n",
            "each epoch's objective value is0.1464717228333904\n",
            "each epoch's objective value is0.14519494434789873\n",
            "each epoch's objective value is0.14396524694077883\n",
            "each epoch's objective value is0.14277989510642117\n",
            "each epoch's objective value is0.14163636625718437\n",
            "each epoch's objective value is0.14053233016993139\n",
            "each epoch's objective value is0.1394656307888076\n",
            "each epoch's objective value is0.1384342700718017\n",
            "each epoch's objective value is0.13743639361574014\n",
            "each epoch's objective value is0.13647027783350796\n",
            "each epoch's objective value is0.13553431848994993\n",
            "each epoch's objective value is0.13462702043028266\n",
            "each epoch's objective value is0.1337469883578874\n",
            "each epoch's objective value is0.13289291853781304\n",
            "each epoch's objective value is0.13206359131882214\n",
            "each epoch's objective value is0.13125786438085227\n",
            "each epoch's objective value is0.13047466662674848\n",
            "each epoch's objective value is0.12971299264738884\n",
            "each epoch's objective value is0.12897189769813494\n",
            "each epoch's objective value is0.12825049313213635\n",
            "each epoch's objective value is0.1275479422425705\n",
            "each epoch's objective value is0.12686345647158023\n",
            "each epoch's objective value is0.12619629194859788\n",
            "each epoch's objective value is0.12554574632503343\n",
            "each epoch's objective value is0.12491115587604353\n",
            "each epoch's objective value is0.12429189284336743\n",
            "each epoch's objective value is0.12368736299607673\n",
            "each epoch's objective value is0.12309700338859954\n",
            "each epoch's objective value is0.12252028029758706\n",
            "each epoch's objective value is0.12195668732113828\n",
            "each epoch's objective value is0.12140574362561371\n",
            "each epoch's objective value is0.12086699232678959\n",
            "each epoch's objective value is0.12033999899344747\n",
            "each epoch's objective value is0.119824350262687\n",
            "each epoch's objective value is0.11931965255731102\n",
            "each epoch's objective value is0.11882553089657344\n",
            "each epoch's objective value is0.11834162779242238\n",
            "each epoch's objective value is0.11786760222412124\n",
            "each epoch's objective value is0.1174031286848003\n",
            "each epoch's objective value is0.1169478962940932\n",
            "each epoch's objective value is0.11650160797154926\n",
            "each epoch's objective value is0.11606397966599673\n",
            "each epoch's objective value is0.11563473963646555\n",
            "each epoch's objective value is0.11521362778066876\n",
            "each epoch's objective value is0.11480039500739372\n",
            "each epoch's objective value is0.11439480264947163\n",
            "each epoch's objective value is0.1139966219142806\n",
            "each epoch's objective value is0.11360563336899576\n",
            "each epoch's objective value is0.11322162645803621\n",
            "each epoch's objective value is0.11284439905036926\n",
            "each epoch's objective value is0.11247375701452618\n",
            "each epoch's objective value is0.11210951381935895\n",
            "each epoch's objective value is0.11175149015872575\n",
            "each epoch's objective value is0.11139951359843846\n",
            "each epoch's objective value is0.11105341824393708\n",
            "each epoch's objective value is0.11071304442727618\n",
            "each epoch's objective value is0.11037823841211813\n",
            "each epoch's objective value is0.11004885211552824\n",
            "each epoch's objective value is0.10972474284545869\n",
            "each epoch's objective value is0.10940577305289152\n",
            "each epoch's objective value is0.10909181009768827\n"
          ]
        }
      ],
      "source": [
        "# Train regularized logistric regression\n",
        "# You should get the optimal weights and a list of objective values by using gradient_descent function.\n",
        "w_optimal_r,loss_r=gradient_descent(x_train,y_train,1E-4,0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bxapp4C2z9l"
      },
      "source": [
        "## 3.2. Stochastic gradient descent (SGD)\n",
        "\n",
        "Define new objective function $Q_i (w) = \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $. \n",
        "\n",
        "The stochastic gradient at $w$ is $g_i = \\frac{\\partial Q_i }{ \\partial w} = -\\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$.\n",
        "\n",
        "You may need to implement a new function to calculate the new objective function and gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I5P1O1v2z9l"
      },
      "outputs": [],
      "source": [
        "# Calculate the objective Q_i and the gradient of Q_i\n",
        "# Inputs:\n",
        "#     w: weights: d-by-1 matrix\n",
        "#     xi: data: 1-by-d matrix\n",
        "#     yi: label: scalar\n",
        "#     lam: scalar, the regularization parameter\n",
        "# Return:\n",
        "#     obj: scalar, the objective Q_i\n",
        "#     g: d-by-1 matrix, gradient of Q_i\n",
        "\n",
        "def stochastic_objective_gradient(w, xi, yi, lam):\n",
        "    #define objective function Q(i)\n",
        "    yx = yi * xi #1-by-d\n",
        "    yxw = float(numpy.dot(yx, w))#scalar\n",
        "\n",
        "    vec = numpy.log(1+numpy.exp(-yxw))  #scalar\n",
        "    reg = lam / 2 *(norm(w)**2) #scalar\n",
        "    Q_i = vec + reg #scalar\n",
        "    #stochastic gradient at w\n",
        "    g_i = -yx.reshape(len(xi),1) / (1+numpy.exp(yxw)) + lam * w# d-by-1\n",
        "\n",
        "    return Q_i, g_i\n",
        "    \n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMhnbHCr2z9l"
      },
      "source": [
        "Hints:\n",
        "1. In every epoch, randomly permute the $n$ samples.\n",
        "2. Each epoch has $n$ iterations. In every iteration, use 1 sample, and compute the gradient and objective using the ``stochastic_objective_gradient`` function. In the next iteration, use the next sample, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jwageOI2z9l"
      },
      "outputs": [],
      "source": [
        "# SGD for solving logistic regression\n",
        "# You will need to do iterative process (loops) to obtain optimal weights in this function\n",
        "\n",
        "# Inputs:\n",
        "#     x: data: n-by-d matrix\n",
        "#     y: label: n-by-1 matrix\n",
        "#     lam: scalar, the regularization parameter\n",
        "#     learning_rate: scalar\n",
        "#     w: weights: d-by-1 matrix, initialization of w\n",
        "#     max_epoch: integer, the maximal epochs\n",
        "# Return:\n",
        "#     \n",
        "#     w: weights: d-by-1 matrix, the solution\n",
        "#     objvals: a record of each epoch's objective value\n",
        "#     Record one objective value per epoch (not per iteration)\n",
        "\n",
        "def sgd(x, y, lam, learning_rate, w=None, max_epoch=100):\n",
        "    \n",
        "    n,d = numpy.shape(x)\n",
        "    objective=[]\n",
        "    w = numpy.zeros((d, 1)) # zero initialization\n",
        "    #epoch\n",
        "    for i in range(max_epoch):\n",
        "        \n",
        "        #random permute samples\n",
        "        index = numpy.random.permutation(n)\n",
        "        x_random=x[index,:]#n-by-d\n",
        "        y_random=y[index,:]#n-by-1\n",
        "        #iteration in each epoch\n",
        "        Q=0\n",
        "        for j in range(n):\n",
        "            Q_i, gradient = stochastic_objective_gradient(w, x_random[j,:], y_random[j,:], lam)\n",
        "            Q += Q_i\n",
        "            w -= learning_rate*gradient#d-by-1\n",
        "        learning_rate *= 0.9\n",
        "        objvals = Q/n\n",
        "        print(\"each epoch's objective value is\" + str(objvals))\n",
        "        \n",
        "        objective.append(objvals)\n",
        "    return w,objective\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tChl8Eb82z9m"
      },
      "source": [
        "Use sgd function to obtain your optimal weights and a list of objective values over each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-08eJut2z9m",
        "outputId": "f925225b-af47-4e9c-f70f-1bcbff4458a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is0.2239275855858968\n",
            "each epoch's objective value is0.12635363687913936\n",
            "each epoch's objective value is0.10880935141552059\n",
            "each epoch's objective value is0.10048562095009257\n",
            "each epoch's objective value is0.09522160068233282\n",
            "each epoch's objective value is0.09175034173485319\n",
            "each epoch's objective value is0.08913614370004377\n",
            "each epoch's objective value is0.08713901054753823\n",
            "each epoch's objective value is0.085573939873688\n",
            "each epoch's objective value is0.08430566956012929\n",
            "each epoch's objective value is0.08325625758978625\n",
            "each epoch's objective value is0.08238759769517978\n",
            "each epoch's objective value is0.08164254848688816\n",
            "each epoch's objective value is0.08102034867260553\n",
            "each epoch's objective value is0.08048495061750245\n",
            "each epoch's objective value is0.08001506928719285\n",
            "each epoch's objective value is0.079615126510477\n",
            "each epoch's objective value is0.07926340933167138\n",
            "each epoch's objective value is0.07895557829830542\n",
            "each epoch's objective value is0.07868304667125403\n",
            "each epoch's objective value is0.0784448442156251\n",
            "each epoch's objective value is0.07823493817454626\n",
            "each epoch's objective value is0.07804876081988384\n",
            "each epoch's objective value is0.07788362095583072\n",
            "each epoch's objective value is0.07773698160883902\n",
            "each epoch's objective value is0.07760612426700463\n",
            "each epoch's objective value is0.07749021938103128\n",
            "each epoch's objective value is0.07738640180837311\n",
            "each epoch's objective value is0.07729396735392804\n",
            "each epoch's objective value is0.07721129530725261\n",
            "each epoch's objective value is0.07713729626446218\n",
            "each epoch's objective value is0.07707124683097957\n",
            "each epoch's objective value is0.07701213345188089\n",
            "each epoch's objective value is0.07695903749104525\n",
            "each epoch's objective value is0.07691157815175156\n",
            "each epoch's objective value is0.07686905512923622\n",
            "each epoch's objective value is0.07683089253976892\n",
            "each epoch's objective value is0.07679663587610357\n",
            "each epoch's objective value is0.07676585996056622\n",
            "each epoch's objective value is0.07673827087064718\n",
            "each epoch's objective value is0.07671348977010767\n",
            "each epoch's objective value is0.07669121995280956\n",
            "each epoch's objective value is0.0766712157301113\n",
            "each epoch's objective value is0.07665323404524156\n",
            "each epoch's objective value is0.07663708679714636\n",
            "each epoch's objective value is0.07662257197659147\n",
            "each epoch's objective value is0.0766095248417744\n",
            "each epoch's objective value is0.07659778784150682\n",
            "each epoch's objective value is0.07658724305931858\n",
            "each epoch's objective value is0.07657775696989125\n",
            "each epoch's objective value is0.07656922526655209\n",
            "each epoch's objective value is0.07656155429451109\n",
            "each epoch's objective value is0.07655465343856559\n",
            "each epoch's objective value is0.07654844721672359\n",
            "each epoch's objective value is0.07654286383144344\n",
            "each epoch's objective value is0.07653784082363681\n",
            "each epoch's objective value is0.07653332275316162\n",
            "each epoch's objective value is0.07652925733975285\n",
            "each epoch's objective value is0.07652559962739343\n",
            "each epoch's objective value is0.07652230862983404\n",
            "each epoch's objective value is0.07651934783622508\n",
            "each epoch's objective value is0.07651668377713228\n",
            "each epoch's objective value is0.07651428638215556\n",
            "each epoch's objective value is0.07651212934818763\n",
            "each epoch's objective value is0.07651018850585209\n",
            "each epoch's objective value is0.07650844185073137\n",
            "each epoch's objective value is0.07650687014946297\n",
            "each epoch's objective value is0.07650545572478717\n",
            "each epoch's objective value is0.07650418293027601\n",
            "each epoch's objective value is0.07650303753538666\n",
            "each epoch's objective value is0.07650200675702575\n",
            "each epoch's objective value is0.07650107914843252\n",
            "each epoch's objective value is0.07650024435909263\n",
            "each epoch's objective value is0.07649949311050873\n",
            "each epoch's objective value is0.07649881703752398\n",
            "each epoch's objective value is0.07649820859375432\n",
            "each epoch's objective value is0.07649766101818471\n",
            "each epoch's objective value is0.07649716821529448\n",
            "each epoch's objective value is0.0764967247264671\n",
            "each epoch's objective value is0.07649632559347597\n",
            "each epoch's objective value is0.07649596638586931\n",
            "each epoch's objective value is0.07649564311171271\n",
            "each epoch's objective value is0.07649535216867155\n",
            "each epoch's objective value is0.07649509032813252\n",
            "each epoch's objective value is0.07649485467663045\n",
            "each epoch's objective value is0.07649464259385144\n",
            "each epoch's objective value is0.07649445172254452\n",
            "each epoch's objective value is0.0764942799405668\n",
            "each epoch's objective value is0.07649412534024322\n",
            "each epoch's objective value is0.07649398620079029\n",
            "each epoch's objective value is0.07649386097737916\n",
            "each epoch's objective value is0.07649374827684073\n",
            "each epoch's objective value is0.07649364684790007\n",
            "each epoch's objective value is0.07649355556255004\n",
            "each epoch's objective value is0.07649347340617596\n",
            "each epoch's objective value is0.07649339946590579\n",
            "each epoch's objective value is0.07649333292005461\n",
            "each epoch's objective value is0.07649327302917003\n",
            "each epoch's objective value is0.0764932191276736\n",
            "each epoch's objective value is0.07649317061647996\n"
          ]
        }
      ],
      "source": [
        "# Train logistic regression\n",
        "# You should get the optimal weights and a list of objective values by using gradient_descent function.\n",
        "lam = 0\n",
        "learning_rate = 0.01\n",
        "w,objective = sgd(x_train, y_train, lam, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHUvDgWc2z9m",
        "outputId": "6b622fe6-ac89-4503-fe45-79fa2e80d8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is0.1440948216057757\n",
            "each epoch's objective value is0.11693102745519593\n",
            "each epoch's objective value is0.11571042851409005\n",
            "each epoch's objective value is0.11303345199892856\n",
            "each epoch's objective value is0.11300302053019005\n",
            "each epoch's objective value is0.11476547886113797\n",
            "each epoch's objective value is0.11171241369126807\n",
            "each epoch's objective value is0.11221644634611348\n",
            "each epoch's objective value is0.11070390853269668\n",
            "each epoch's objective value is0.11063903132392738\n",
            "each epoch's objective value is0.10975345971240842\n",
            "each epoch's objective value is0.10987707047323282\n",
            "each epoch's objective value is0.10956478073513394\n",
            "each epoch's objective value is0.10892280086467006\n",
            "each epoch's objective value is0.10881603133783302\n",
            "each epoch's objective value is0.1083100493746195\n",
            "each epoch's objective value is0.10835165792109254\n",
            "each epoch's objective value is0.10820326932392367\n",
            "each epoch's objective value is0.10797567308362105\n",
            "each epoch's objective value is0.10781421225496937\n",
            "each epoch's objective value is0.10767305925775135\n",
            "each epoch's objective value is0.10732453662204541\n",
            "each epoch's objective value is0.10746103464409955\n",
            "each epoch's objective value is0.10725460957306357\n",
            "each epoch's objective value is0.10721245713158398\n",
            "each epoch's objective value is0.10709059140820387\n",
            "each epoch's objective value is0.10702192255561085\n",
            "each epoch's objective value is0.10695715867495105\n",
            "each epoch's objective value is0.10687978021941132\n",
            "each epoch's objective value is0.10681739256514561\n",
            "each epoch's objective value is0.10675095865565475\n",
            "each epoch's objective value is0.10671331394230783\n",
            "each epoch's objective value is0.10667557649056396\n",
            "each epoch's objective value is0.10663495133280985\n",
            "each epoch's objective value is0.10659929789567794\n",
            "each epoch's objective value is0.1065673799557201\n",
            "each epoch's objective value is0.10653475824752828\n",
            "each epoch's objective value is0.10651029134702068\n",
            "each epoch's objective value is0.10648086877648923\n",
            "each epoch's objective value is0.10646647717372944\n",
            "each epoch's objective value is0.10644681320730599\n",
            "each epoch's objective value is0.10643077482203125\n",
            "each epoch's objective value is0.10641248211661206\n",
            "each epoch's objective value is0.10640026630078339\n",
            "each epoch's objective value is0.10638779581039094\n",
            "each epoch's objective value is0.1063769172790819\n",
            "each epoch's objective value is0.10636646072041418\n",
            "each epoch's objective value is0.10635741677299133\n",
            "each epoch's objective value is0.10634900299493776\n",
            "each epoch's objective value is0.10634144926556022\n",
            "each epoch's objective value is0.10633490684253437\n",
            "each epoch's objective value is0.10632892337040273\n",
            "each epoch's objective value is0.10632352707652817\n",
            "each epoch's objective value is0.1063185914523192\n",
            "each epoch's objective value is0.10631418830274347\n",
            "each epoch's objective value is0.10631018520582852\n",
            "each epoch's objective value is0.1063066464948133\n",
            "each epoch's objective value is0.10630341130947026\n",
            "each epoch's objective value is0.10630053505433444\n",
            "each epoch's objective value is0.10629791029508827\n",
            "each epoch's objective value is0.10629556192247434\n",
            "each epoch's objective value is0.10629345128959691\n",
            "each epoch's objective value is0.10629155784176608\n",
            "each epoch's objective value is0.10628983495953563\n",
            "each epoch's objective value is0.10628829804307706\n",
            "each epoch's objective value is0.10628691613934434\n",
            "each epoch's objective value is0.10628566601863043\n",
            "each epoch's objective value is0.10628454377524477\n",
            "each epoch's objective value is0.10628352786385767\n",
            "each epoch's objective value is0.10628262066439591\n",
            "each epoch's objective value is0.10628180473513107\n",
            "each epoch's objective value is0.10628106637812368\n",
            "each epoch's objective value is0.10628040333799382\n",
            "each epoch's objective value is0.10627980617555655\n",
            "each epoch's objective value is0.10627926721282074\n",
            "each epoch's objective value is0.1062787849231892\n",
            "each epoch's objective value is0.10627834731611759\n",
            "each epoch's objective value is0.1062779575315918\n",
            "each epoch's objective value is0.1062776055344404\n",
            "each epoch's objective value is0.10627728828226372\n",
            "each epoch's objective value is0.10627700269213687\n",
            "each epoch's objective value is0.10627674544698144\n",
            "each epoch's objective value is0.10627651420474409\n",
            "each epoch's objective value is0.10627630565106837\n",
            "each epoch's objective value is0.10627611859213759\n",
            "each epoch's objective value is0.10627594969200432\n",
            "each epoch's objective value is0.10627579816316414\n",
            "each epoch's objective value is0.10627566145777352\n",
            "each epoch's objective value is0.10627553861431635\n",
            "each epoch's objective value is0.10627542786455899\n",
            "each epoch's objective value is0.10627532828104594\n",
            "each epoch's objective value is0.10627523865948584\n",
            "each epoch's objective value is0.10627515800096513\n",
            "each epoch's objective value is0.10627508540403742\n",
            "each epoch's objective value is0.10627502004444482\n",
            "each epoch's objective value is0.1062749612544874\n",
            "each epoch's objective value is0.10627490831945532\n",
            "each epoch's objective value is0.10627486068074489\n",
            "each epoch's objective value is0.10627481781611593\n",
            "each epoch's objective value is0.10627477921449865\n"
          ]
        }
      ],
      "source": [
        "# Train regularized logistric regression\n",
        "# You should get the optimal weights and a list of objective values by using gradient_descent function.\n",
        "lam = 0.01\n",
        "learning_rate = 0.1\n",
        "w,objective = sgd(x_train, y_train, lam, learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPB4K9qt2z9m"
      },
      "source": [
        "## 3.3 Mini-Batch Gradient Descent (MBGD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0HK3TOb2z9m"
      },
      "source": [
        "Define $Q_I (w) = \\frac{1}{b} \\sum_{i \\in I} \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $, where $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
        "\n",
        "The stochastic gradient at $w$ is $g_I = \\frac{\\partial Q_I }{ \\partial w} = \\frac{1}{b} \\sum_{i \\in I} \\frac{- y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$.\n",
        "\n",
        "You may need to implement a new function to calculate the new objective function and gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOo7IQDs2z9n"
      },
      "outputs": [],
      "source": [
        "# Calculate the objective Q_I and the gradient of Q_I\n",
        "# Inputs:\n",
        "#     w: weights: d-by-b matrix\n",
        "#     xi: data: b-by-d matrix\n",
        "#     yi: label: scalar\n",
        "#     lam: scalar, the regularization parameter\n",
        "# Return:\n",
        "#     obj: scalar, the objective Q_i\n",
        "#     g: d-by-1 matrix, gradient of Q_i\n",
        "\n",
        "def mb_objective_gradient(w, xi, yi, lam):\n",
        "    yx = numpy.multiply(yi,xi) #b-by-d \n",
        "    func0 = numpy.log(1+numpy.exp(-numpy.dot(yx,w))) #b-by-1\n",
        "    func0_mean = numpy.mean(func0,axis = 0)#scalar\n",
        "    Q_I = func0_mean + lam/2*(norm(w))**2#scalar\n",
        "    func1 = numpy.divide(-yx, 1+numpy.exp(numpy.dot(yx,w)))# b-by-d\n",
        "    g_I = numpy.mean(func1,axis=0).reshape(d,1) + lam * w # d-by-1\n",
        "    return Q_I, g_I\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsk8URV_2z9n"
      },
      "source": [
        "Hints:\n",
        "1. In every epoch, randomly permute the $n$ samples (just like SGD).\n",
        "2. Each epoch has $\\frac{n}{b}$ iterations. In every iteration, use $b$ samples, and compute the gradient and objective using the ``mb_objective_gradient`` function. In the next iteration, use the next $b$ samples, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F40AjVyC2z9n"
      },
      "outputs": [],
      "source": [
        "# MBGD for solving logistic regression\n",
        "# You will need to do iterative process (loops) to obtain optimal weights in this function\n",
        "\n",
        "# Inputs:\n",
        "#     x: data: n-by-d matrix\n",
        "#     y: label: n-by-1 matrix\n",
        "#     lam: scalar, the regularization parameter\n",
        "#     learning_rate: scalar\n",
        "#     w: weights: d-by-1 matrix, initialization of w\n",
        "#     max_epoch: integer, the maximal epochs\n",
        "# Return:\n",
        "#     w: weights: d-by-1 matrix, the solution\n",
        "#     objvals: a record of each epoch's objective value\n",
        "#     Record one objective value per epoch (not per iteration)\n",
        "\n",
        "def mbgd(x, y, lam, learning_rate, w, max_epoch=100):\n",
        "    n,d = numpy.shape(x)\n",
        "    objvals=[]\n",
        "    w = numpy.zeros((d, 1))#initialization of w\n",
        "    b = 32 #set the value of b\n",
        "    #epoch\n",
        "    for i in range(max_epoch):\n",
        "        Q = 0\n",
        "        #random permute samples\n",
        "        index = numpy.random.permutation(n)\n",
        "        x_random=x[index,:]#n-by-d\n",
        "        y_random=y[index,:]#n-by-1\n",
        "        if n % d != 0:\n",
        "            iter = int((n - (n%b))/b + 1)\n",
        "        else:\n",
        "            iter = int(n/b)\n",
        "        for j in range(iter):\n",
        "            if j < iter:\n",
        "                Q_I,g_I = mb_objective_gradient(w,x[b*j:b*(j+1),:],y[b*j:b*(j+1),:],lam)\n",
        "            else:\n",
        "                Q_I,g_I = mb_objective_gradient(w,x[b*j:n,:],y[b*j:n,:],lam)\n",
        "            Q += Q_I\n",
        "            w -= learning_rate*g_I\n",
        "        objval=Q/iter\n",
        "        print(\"each epoch's objective value is\" + str(objval))\n",
        "        objvals.append(objval)\n",
        "        learning_rate *= 0.9\n",
        "    return w, objvals\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEDnozYp2z9n"
      },
      "source": [
        "Use mbgd function to obtain your optimal weights and a list of objective values over each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKsP59Xz2z9n",
        "outputId": "a9e73b83-74ea-4d2a-b5da-6c18903f2da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is[0.33012411]\n",
            "each epoch's objective value is[0.18277917]\n",
            "each epoch's objective value is[0.15139856]\n",
            "each epoch's objective value is[0.13592858]\n",
            "each epoch's objective value is[0.12652941]\n",
            "each epoch's objective value is[0.12016517]\n",
            "each epoch's objective value is[0.11555875]\n",
            "each epoch's objective value is[0.11207102]\n",
            "each epoch's objective value is[0.10934358]\n",
            "each epoch's objective value is[0.10715844]\n",
            "each epoch's objective value is[0.10537472]\n",
            "each epoch's objective value is[0.10389696]\n",
            "each epoch's objective value is[0.10265794]\n",
            "each epoch's objective value is[0.10160886]\n",
            "each epoch's objective value is[0.10071334]\n",
            "each epoch's objective value is[0.09994367]\n",
            "each epoch's objective value is[0.09927832]\n",
            "each epoch's objective value is[0.09870031]\n",
            "each epoch's objective value is[0.09819604]\n",
            "each epoch's objective value is[0.0977545]\n",
            "each epoch's objective value is[0.09736665]\n",
            "each epoch's objective value is[0.09702501]\n",
            "each epoch's objective value is[0.09672337]\n",
            "each epoch's objective value is[0.09645646]\n",
            "each epoch's objective value is[0.09621985]\n",
            "each epoch's objective value is[0.09600975]\n",
            "each epoch's objective value is[0.09582292]\n",
            "each epoch's objective value is[0.09565658]\n",
            "each epoch's objective value is[0.0955083]\n",
            "each epoch's objective value is[0.09537599]\n",
            "each epoch's objective value is[0.09525782]\n",
            "each epoch's objective value is[0.0951522]\n",
            "each epoch's objective value is[0.09505772]\n",
            "each epoch's objective value is[0.09497316]\n",
            "each epoch's objective value is[0.09489744]\n",
            "each epoch's objective value is[0.09482959]\n",
            "each epoch's objective value is[0.09476877]\n",
            "each epoch's objective value is[0.09471422]\n",
            "each epoch's objective value is[0.09466529]\n",
            "each epoch's objective value is[0.09462138]\n",
            "each epoch's objective value is[0.09458196]\n",
            "each epoch's objective value is[0.09454657]\n",
            "each epoch's objective value is[0.09451478]\n",
            "each epoch's objective value is[0.09448623]\n",
            "each epoch's objective value is[0.09446057]\n",
            "each epoch's objective value is[0.09443752]\n",
            "each epoch's objective value is[0.0944168]\n",
            "each epoch's objective value is[0.09439817]\n",
            "each epoch's objective value is[0.09438142]\n",
            "each epoch's objective value is[0.09436637]\n",
            "each epoch's objective value is[0.09435283]\n",
            "each epoch's objective value is[0.09434066]\n",
            "each epoch's objective value is[0.09432971]\n",
            "each epoch's objective value is[0.09431986]\n",
            "each epoch's objective value is[0.094311]\n",
            "each epoch's objective value is[0.09430304]\n",
            "each epoch's objective value is[0.09429587]\n",
            "each epoch's objective value is[0.09428942]\n",
            "each epoch's objective value is[0.09428362]\n",
            "each epoch's objective value is[0.0942784]\n",
            "each epoch's objective value is[0.09427371]\n",
            "each epoch's objective value is[0.09426948]\n",
            "each epoch's objective value is[0.09426568]\n",
            "each epoch's objective value is[0.09426226]\n",
            "each epoch's objective value is[0.09425918]\n",
            "each epoch's objective value is[0.09425641]\n",
            "each epoch's objective value is[0.09425392]\n",
            "each epoch's objective value is[0.09425168]\n",
            "each epoch's objective value is[0.09424966]\n",
            "each epoch's objective value is[0.09424784]\n",
            "each epoch's objective value is[0.09424621]\n",
            "each epoch's objective value is[0.09424474]\n",
            "each epoch's objective value is[0.09424341]\n",
            "each epoch's objective value is[0.09424222]\n",
            "each epoch's objective value is[0.09424115]\n",
            "each epoch's objective value is[0.09424019]\n",
            "each epoch's objective value is[0.09423932]\n",
            "each epoch's objective value is[0.09423854]\n",
            "each epoch's objective value is[0.09423783]\n",
            "each epoch's objective value is[0.0942372]\n",
            "each epoch's objective value is[0.09423663]\n",
            "each epoch's objective value is[0.09423612]\n",
            "each epoch's objective value is[0.09423566]\n",
            "each epoch's objective value is[0.09423524]\n",
            "each epoch's objective value is[0.09423487]\n",
            "each epoch's objective value is[0.09423453]\n",
            "each epoch's objective value is[0.09423423]\n",
            "each epoch's objective value is[0.09423396]\n",
            "each epoch's objective value is[0.09423371]\n",
            "each epoch's objective value is[0.09423349]\n",
            "each epoch's objective value is[0.09423329]\n",
            "each epoch's objective value is[0.09423311]\n",
            "each epoch's objective value is[0.09423295]\n",
            "each epoch's objective value is[0.09423281]\n",
            "each epoch's objective value is[0.09423268]\n",
            "each epoch's objective value is[0.09423256]\n",
            "each epoch's objective value is[0.09423246]\n",
            "each epoch's objective value is[0.09423236]\n",
            "each epoch's objective value is[0.09423228]\n",
            "each epoch's objective value is[0.0942322]\n"
          ]
        }
      ],
      "source": [
        "# Train logistic regression\n",
        "# You should get the optimal weights and a list of objective values by using gradient_descent function.\n",
        "lam = 0\n",
        "learning_rate = 0.1\n",
        "w,obj=mbgd(x_train, y_train, lam, learning_rate, w=None, max_epoch=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18FDWviX2z9o",
        "outputId": "2303a600-0c5b-4617-a73d-328205efd3b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is[0.33200064]\n",
            "each epoch's objective value is[0.18811835]\n",
            "each epoch's objective value is[0.15911575]\n",
            "each epoch's objective value is[0.14543229]\n",
            "each epoch's objective value is[0.13744215]\n",
            "each epoch's objective value is[0.13222266]\n",
            "each epoch's objective value is[0.12856499]\n",
            "each epoch's objective value is[0.12587496]\n",
            "each epoch's objective value is[0.12382554]\n",
            "each epoch's objective value is[0.12222162]\n",
            "each epoch's objective value is[0.12093957]\n",
            "each epoch's objective value is[0.11989726]\n",
            "each epoch's objective value is[0.11903798]\n",
            "each epoch's objective value is[0.11832137]\n",
            "each epoch's objective value is[0.11771791]\n",
            "each epoch's objective value is[0.11720554]\n",
            "each epoch's objective value is[0.11676743]\n",
            "each epoch's objective value is[0.11639055]\n",
            "each epoch's objective value is[0.11606463]\n",
            "each epoch's objective value is[0.1157815]\n",
            "each epoch's objective value is[0.11553455]\n",
            "each epoch's objective value is[0.11531842]\n",
            "each epoch's objective value is[0.11512867]\n",
            "each epoch's objective value is[0.11496164]\n",
            "each epoch's objective value is[0.11481424]\n",
            "each epoch's objective value is[0.11468391]\n",
            "each epoch's objective value is[0.11456844]\n",
            "each epoch's objective value is[0.11446598]\n",
            "each epoch's objective value is[0.11437492]\n",
            "each epoch's objective value is[0.11429388]\n",
            "each epoch's objective value is[0.11422169]\n",
            "each epoch's objective value is[0.1141573]\n",
            "each epoch's objective value is[0.11409982]\n",
            "each epoch's objective value is[0.11404846]\n",
            "each epoch's objective value is[0.11400254]\n",
            "each epoch's objective value is[0.11396146]\n",
            "each epoch's objective value is[0.11392468]\n",
            "each epoch's objective value is[0.11389173]\n",
            "each epoch's objective value is[0.11386221]\n",
            "each epoch's objective value is[0.11383573]\n",
            "each epoch's objective value is[0.11381199]\n",
            "each epoch's objective value is[0.11379069]\n",
            "each epoch's objective value is[0.11377157]\n",
            "each epoch's objective value is[0.11375441]\n",
            "each epoch's objective value is[0.113739]\n",
            "each epoch's objective value is[0.11372515]\n",
            "each epoch's objective value is[0.11371272]\n",
            "each epoch's objective value is[0.11370154]\n",
            "each epoch's objective value is[0.1136915]\n",
            "each epoch's objective value is[0.11368247]\n",
            "each epoch's objective value is[0.11367436]\n",
            "each epoch's objective value is[0.11366706]\n",
            "each epoch's objective value is[0.1136605]\n",
            "each epoch's objective value is[0.11365461]\n",
            "each epoch's objective value is[0.1136493]\n",
            "each epoch's objective value is[0.11364453]\n",
            "each epoch's objective value is[0.11364024]\n",
            "each epoch's objective value is[0.11363638]\n",
            "each epoch's objective value is[0.11363291]\n",
            "each epoch's objective value is[0.11362979]\n",
            "each epoch's objective value is[0.11362698]\n",
            "each epoch's objective value is[0.11362445]\n",
            "each epoch's objective value is[0.11362218]\n",
            "each epoch's objective value is[0.11362013]\n",
            "each epoch's objective value is[0.11361829]\n",
            "each epoch's objective value is[0.11361663]\n",
            "each epoch's objective value is[0.11361514]\n",
            "each epoch's objective value is[0.1136138]\n",
            "each epoch's objective value is[0.11361259]\n",
            "each epoch's objective value is[0.11361151]\n",
            "each epoch's objective value is[0.11361053]\n",
            "each epoch's objective value is[0.11360965]\n",
            "each epoch's objective value is[0.11360886]\n",
            "each epoch's objective value is[0.11360815]\n",
            "each epoch's objective value is[0.11360751]\n",
            "each epoch's objective value is[0.11360693]\n",
            "each epoch's objective value is[0.11360641]\n",
            "each epoch's objective value is[0.11360594]\n",
            "each epoch's objective value is[0.11360552]\n",
            "each epoch's objective value is[0.11360515]\n",
            "each epoch's objective value is[0.11360481]\n",
            "each epoch's objective value is[0.1136045]\n",
            "each epoch's objective value is[0.11360422]\n",
            "each epoch's objective value is[0.11360398]\n",
            "each epoch's objective value is[0.11360375]\n",
            "each epoch's objective value is[0.11360355]\n",
            "each epoch's objective value is[0.11360337]\n",
            "each epoch's objective value is[0.11360321]\n",
            "each epoch's objective value is[0.11360306]\n",
            "each epoch's objective value is[0.11360293]\n",
            "each epoch's objective value is[0.11360281]\n",
            "each epoch's objective value is[0.1136027]\n",
            "each epoch's objective value is[0.11360261]\n",
            "each epoch's objective value is[0.11360252]\n",
            "each epoch's objective value is[0.11360244]\n",
            "each epoch's objective value is[0.11360237]\n",
            "each epoch's objective value is[0.11360231]\n",
            "each epoch's objective value is[0.11360225]\n",
            "each epoch's objective value is[0.1136022]\n",
            "each epoch's objective value is[0.11360216]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([[-0.40971541],\n",
              "        [-0.36708672],\n",
              "        [-0.40577701],\n",
              "        [-0.40885301],\n",
              "        [-0.13541838],\n",
              "        [-0.15187571],\n",
              "        [-0.32252353],\n",
              "        [-0.42589656],\n",
              "        [-0.14161975],\n",
              "        [ 0.16566637],\n",
              "        [-0.35264837],\n",
              "        [ 0.00785426],\n",
              "        [-0.29536483],\n",
              "        [-0.32518716],\n",
              "        [ 0.00203704],\n",
              "        [ 0.12579192],\n",
              "        [ 0.09844021],\n",
              "        [-0.04694441],\n",
              "        [ 0.0478326 ],\n",
              "        [ 0.17069324],\n",
              "        [-0.50544755],\n",
              "        [-0.46128   ],\n",
              "        [-0.47780655],\n",
              "        [-0.48034508],\n",
              "        [-0.32651608],\n",
              "        [-0.22383052],\n",
              "        [-0.31017743],\n",
              "        [-0.4546639 ],\n",
              "        [-0.33828975],\n",
              "        [-0.14093926]]),\n",
              " [array([0.33200064]),\n",
              "  array([0.18811835]),\n",
              "  array([0.15911575]),\n",
              "  array([0.14543229]),\n",
              "  array([0.13744215]),\n",
              "  array([0.13222266]),\n",
              "  array([0.12856499]),\n",
              "  array([0.12587496]),\n",
              "  array([0.12382554]),\n",
              "  array([0.12222162]),\n",
              "  array([0.12093957]),\n",
              "  array([0.11989726]),\n",
              "  array([0.11903798]),\n",
              "  array([0.11832137]),\n",
              "  array([0.11771791]),\n",
              "  array([0.11720554]),\n",
              "  array([0.11676743]),\n",
              "  array([0.11639055]),\n",
              "  array([0.11606463]),\n",
              "  array([0.1157815]),\n",
              "  array([0.11553455]),\n",
              "  array([0.11531842]),\n",
              "  array([0.11512867]),\n",
              "  array([0.11496164]),\n",
              "  array([0.11481424]),\n",
              "  array([0.11468391]),\n",
              "  array([0.11456844]),\n",
              "  array([0.11446598]),\n",
              "  array([0.11437492]),\n",
              "  array([0.11429388]),\n",
              "  array([0.11422169]),\n",
              "  array([0.1141573]),\n",
              "  array([0.11409982]),\n",
              "  array([0.11404846]),\n",
              "  array([0.11400254]),\n",
              "  array([0.11396146]),\n",
              "  array([0.11392468]),\n",
              "  array([0.11389173]),\n",
              "  array([0.11386221]),\n",
              "  array([0.11383573]),\n",
              "  array([0.11381199]),\n",
              "  array([0.11379069]),\n",
              "  array([0.11377157]),\n",
              "  array([0.11375441]),\n",
              "  array([0.113739]),\n",
              "  array([0.11372515]),\n",
              "  array([0.11371272]),\n",
              "  array([0.11370154]),\n",
              "  array([0.1136915]),\n",
              "  array([0.11368247]),\n",
              "  array([0.11367436]),\n",
              "  array([0.11366706]),\n",
              "  array([0.1136605]),\n",
              "  array([0.11365461]),\n",
              "  array([0.1136493]),\n",
              "  array([0.11364453]),\n",
              "  array([0.11364024]),\n",
              "  array([0.11363638]),\n",
              "  array([0.11363291]),\n",
              "  array([0.11362979]),\n",
              "  array([0.11362698]),\n",
              "  array([0.11362445]),\n",
              "  array([0.11362218]),\n",
              "  array([0.11362013]),\n",
              "  array([0.11361829]),\n",
              "  array([0.11361663]),\n",
              "  array([0.11361514]),\n",
              "  array([0.1136138]),\n",
              "  array([0.11361259]),\n",
              "  array([0.11361151]),\n",
              "  array([0.11361053]),\n",
              "  array([0.11360965]),\n",
              "  array([0.11360886]),\n",
              "  array([0.11360815]),\n",
              "  array([0.11360751]),\n",
              "  array([0.11360693]),\n",
              "  array([0.11360641]),\n",
              "  array([0.11360594]),\n",
              "  array([0.11360552]),\n",
              "  array([0.11360515]),\n",
              "  array([0.11360481]),\n",
              "  array([0.1136045]),\n",
              "  array([0.11360422]),\n",
              "  array([0.11360398]),\n",
              "  array([0.11360375]),\n",
              "  array([0.11360355]),\n",
              "  array([0.11360337]),\n",
              "  array([0.11360321]),\n",
              "  array([0.11360306]),\n",
              "  array([0.11360293]),\n",
              "  array([0.11360281]),\n",
              "  array([0.1136027]),\n",
              "  array([0.11360261]),\n",
              "  array([0.11360252]),\n",
              "  array([0.11360244]),\n",
              "  array([0.11360237]),\n",
              "  array([0.11360231]),\n",
              "  array([0.11360225]),\n",
              "  array([0.1136022]),\n",
              "  array([0.11360216])])"
            ]
          },
          "execution_count": 1173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train regularized logistric regression\n",
        "# You should get the optimal weights and a list of objective values by using gradient_descent function.\n",
        "lam = 0.01\n",
        "learning_rate = 0.1\n",
        "mbgd(x_train, y_train, lam, learning_rate, w=None, max_epoch=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zl9cs2V2z9o"
      },
      "source": [
        "# 4. Compare GD, SGD, MBGD\n",
        "\n",
        "### Plot objective function values against epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZvCmrbr2z9o",
        "outputId": "5eeb5af3-a5fb-4009-cc76-fb35beb1d33d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fed0876bdf0>"
            ]
          },
          "execution_count": 1178,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(range(len(obj)), obj, label = \"MBGD\")\n",
        "plt.plot(range(len(objective)),objective, label = \"SGD\")\n",
        "plt.plot(range(len(loss_r)), loss_r, label = \"GD\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCOXjXdg2z9o"
      },
      "source": [
        "# 5. Prediction\n",
        "### Compare the training and testing accuracy for logistic regression and regularized logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx6Bymtq2z9o"
      },
      "outputs": [],
      "source": [
        "# Predict class label\n",
        "# Inputs:\n",
        "#     w: weights: d-by-1 matrix\n",
        "#     X: data: m-by-d matrix\n",
        "# Return:\n",
        "#     f: m-by-1 matrix, the predictions\n",
        "def predict(w, X):\n",
        "    f = numpy.sign(numpy.dot(X, w))\n",
        "    return f\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1dcmHIv2z9p",
        "outputId": "1651fdc8-aab4-4c36-b0be-12d7779562f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training error of logistric regression is:0.02637362637362639\n",
            "The accuracy of logistric regression is:0.9736263736263736\n",
            "The training error of regularized logistric regression is:0.02637362637362639\n",
            "The accuracy of regularized logistric regression is:0.9736263736263736\n"
          ]
        }
      ],
      "source": [
        "# evaluate training error of logistric regression and regularized version\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred1 = predict(w_optimal, x_train)\n",
        "acc1 = accuracy_score(y_train, y_pred1)\n",
        "y_pred2 = predict(w_optimal_r, x_train)\n",
        "acc2 = accuracy_score(y_train, y_pred2)\n",
        "print(\"The training error of logistric regression is:\"+str(1-acc1)+\"\\n\"\"The accuracy of logistric regression is:\"+str(acc1))\n",
        "print(\"The training error of regularized logistric regression is:\"+str(1-acc2)+\"\\n\"\"The accuracy of regularized logistric regression is:\"+str(acc2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzfKyNUa2z9p",
        "outputId": "e5419dba-a0c8-49f2-a852-2f89131f2b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training error of logistric regression is:0.03508771929824561\n",
            "The accuracy of logistric regression is:0.9649122807017544\n",
            "The training error of regularized logistric regression is:0.03508771929824561\n",
            "The accuracy of regularized logistric regression is:0.9649122807017544\n"
          ]
        }
      ],
      "source": [
        "# evaluate testing error of logistric regression and regularized version\n",
        "f1_test = predict(w_optimal, x_test)\n",
        "acc1_test = accuracy_score(y_test, f1_test)\n",
        "f2_test = predict(w_optimal_r, x_test)\n",
        "acc2_test = accuracy_score(y_test, f2_test)\n",
        "print(\"The training error of logistric regression is:\"+str(1-acc1_test)+\"\\n\"\"The accuracy of logistric regression is:\"+str(acc1_test))\n",
        "print(\"The training error of regularized logistric regression is:\"+str(1-acc2_test)+\"\\n\"\"The accuracy of regularized logistric regression is:\"+str(acc2_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P4BYe372z9p"
      },
      "source": [
        "# 6. Parameters tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7MX6zXQ2z9p"
      },
      "source": [
        "### In this section, you may try different combinations of parameters (regularization value, learning rate, etc) to see their effects on the model. (Open ended question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rqpvWEU2z9p",
        "outputId": "2b5119ad-52c2-400c-db8c-9981cd0b163d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is0.5250103198478463\n",
            "each epoch's objective value is0.44210595963838306\n",
            "each epoch's objective value is0.39269160402225467\n",
            "each epoch's objective value is0.3595360386254994\n",
            "each epoch's objective value is0.3356031963875347\n",
            "each epoch's objective value is0.3174560414753522\n",
            "each epoch's objective value is0.30320111516678966\n",
            "each epoch's objective value is0.29170272030807753\n",
            "each epoch's objective value is0.28223502519881777\n",
            "each epoch's objective value is0.27431068491553096\n",
            "each epoch's objective value is0.26758928432310347\n",
            "each epoch's objective value is0.26182519917933333\n",
            "each epoch's objective value is0.25683632879675444\n",
            "each epoch's objective value is0.2524845250536895\n",
            "each epoch's objective value is0.2486628923777241\n",
            "each epoch's objective value is0.2452872881365614\n",
            "each epoch's objective value is0.24229048007159176\n",
            "each epoch's objective value is0.2396180350244165\n",
            "each epoch's objective value is0.2372253654073451\n",
            "each epoch's objective value is0.23507556783887756\n",
            "each epoch's objective value is0.2331378149957003\n",
            "each epoch's objective value is0.23138614096477897\n",
            "each epoch's objective value is0.22979851117434313\n",
            "each epoch's objective value is0.22835610126575684\n",
            "each epoch's objective value is0.2270427315106057\n",
            "each epoch's objective value is0.22584441850898396\n",
            "each epoch's objective value is0.22474901636778716\n",
            "each epoch's objective value is0.2237459269006869\n",
            "each epoch's objective value is0.222825863615651\n",
            "each epoch's objective value is0.2219806580199561\n",
            "each epoch's objective value is0.2212030995167525\n",
            "each epoch's objective value is0.22048680218986355\n",
            "each epoch's objective value is0.2198260932797941\n",
            "each epoch's objective value is0.2192159192866656\n",
            "each epoch's objective value is0.21865176649552426\n",
            "each epoch's objective value is0.21812959337771615\n",
            "each epoch's objective value is0.21764577283023084\n",
            "each epoch's objective value is0.21719704261040187\n",
            "each epoch's objective value is0.2167804626334535\n",
            "each epoch's objective value is0.21639337804529313\n",
            "each epoch's objective value is0.2160333871776952\n",
            "each epoch's objective value is0.2156983136488932\n",
            "each epoch's objective value is0.21538618199812976\n",
            "each epoch's objective value is0.2150951963444016\n",
            "each epoch's objective value is0.214823721642476\n",
            "each epoch's objective value is0.21457026717708705\n",
            "each epoch's objective value is0.21433347199205552\n",
            "each epoch's objective value is0.21411209199723547\n",
            "each epoch's objective value is0.21390498853454232\n",
            "each epoch's objective value is0.21371111821630218\n",
            "each epoch's objective value is0.21352952387595148\n",
            "each epoch's objective value is0.2133593264936403\n",
            "each epoch's objective value is0.21319971797829498\n",
            "each epoch's objective value is0.21304995470378632\n",
            "each epoch's objective value is0.2129093517105185\n",
            "each epoch's objective value is0.21277727749539815\n",
            "each epoch's objective value is0.21265314932309853\n",
            "each epoch's objective value is0.2125364290000618\n",
            "each epoch's objective value is0.21242661906001742\n",
            "each epoch's objective value is0.21232325931610652\n",
            "each epoch's objective value is0.21222592374016253\n",
            "each epoch's objective value is0.2121342176344203\n",
            "each epoch's objective value is0.21204777506502603\n",
            "each epoch's objective value is0.21196625653028553\n",
            "each epoch's objective value is0.21188934683969726\n",
            "each epoch's objective value is0.2118167531825299\n",
            "each epoch's objective value is0.2117482033670798\n",
            "each epoch's objective value is0.21168344421382504\n",
            "each epoch's objective value is0.21162224008752484\n",
            "each epoch's objective value is0.21156437155491942\n",
            "each epoch's objective value is0.2115096341561067\n",
            "each epoch's objective value is0.21145783727892437\n",
            "each epoch's objective value is0.211408803126773\n",
            "each epoch's objective value is0.2113623657712993\n",
            "each epoch's objective value is0.21131837028222705\n",
            "each epoch's objective value is0.2112766719273988\n",
            "each epoch's objective value is0.21123713543677852\n",
            "each epoch's objective value is0.21119963432477917\n",
            "each epoch's objective value is0.21116405026582655\n",
            "each epoch's objective value is0.21113027251855906\n",
            "each epoch's objective value is0.21109819739450097\n",
            "each epoch's objective value is0.21106772776743843\n",
            "each epoch's objective value is0.21103877262007803\n",
            "each epoch's objective value is0.21101124662488493\n",
            "each epoch's objective value is0.2109850697562785\n",
            "each epoch's objective value is0.21096016693162123\n",
            "each epoch's objective value is0.21093646767866508\n",
            "each epoch's objective value is0.21091390582732694\n",
            "each epoch's objective value is0.21089241922385282\n",
            "each epoch's objective value is0.21087194946559853\n",
            "each epoch's objective value is0.2108524416548092\n",
            "each epoch's objective value is0.21083384416991702\n",
            "each epoch's objective value is0.21081610845300294\n",
            "each epoch's objective value is0.2107991888121835\n",
            "each epoch's objective value is0.2107830422377843\n",
            "each epoch's objective value is0.21076762823125977\n",
            "each epoch's objective value is0.21075290864590068\n",
            "each epoch's objective value is0.21073884753845223\n",
            "each epoch's objective value is0.21072541103083392\n",
            "each epoch's objective value is0.21071256718121878\n",
            "0.9714285714285714 0.9649122807017544\n"
          ]
        }
      ],
      "source": [
        "#for GD, set the lam as 0.1 and learning_rate as 0.1\n",
        "w_optimal_r1,loss_r1=gradient_descent(x_train,y_train,0.1,0.1)\n",
        "y_pred3 = predict(w_optimal_r1, x_train)\n",
        "acc3 = accuracy_score(y_train, y_pred3)\n",
        "y_pred3_test = predict(w_optimal_r1, x_test)\n",
        "acc3_test = accuracy_score(y_test, y_pred3_test)\n",
        "print(acc3,acc3_test)\n",
        "# training_accuracy = 0.5956043956043956; test_accuracy = 0.5789473684210527"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIe_RRqu2z9p",
        "outputId": "2df24e02-2039-4925-ca97-c0283afd7646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is0.26786501984259103\n",
            "each epoch's objective value is0.21397760388629714\n",
            "each epoch's objective value is0.2126558851503678\n",
            "each epoch's objective value is0.21218616584496755\n",
            "each epoch's objective value is0.21176896560193723\n",
            "each epoch's objective value is0.21169675581323885\n",
            "each epoch's objective value is0.2117069904308007\n",
            "each epoch's objective value is0.21141742222387644\n",
            "each epoch's objective value is0.21145648710303855\n",
            "each epoch's objective value is0.2113014318497886\n",
            "each epoch's objective value is0.21116646230330147\n",
            "each epoch's objective value is0.21115705892804085\n",
            "each epoch's objective value is0.21099384387324377\n",
            "each epoch's objective value is0.21102441911650968\n",
            "each epoch's objective value is0.21091346463544805\n",
            "each epoch's objective value is0.2108904774020609\n",
            "each epoch's objective value is0.21084829300920296\n",
            "each epoch's objective value is0.2107934115736217\n",
            "each epoch's objective value is0.21075230748803214\n",
            "each epoch's objective value is0.210713632478876\n",
            "each epoch's objective value is0.21068876139310597\n",
            "each epoch's objective value is0.21065154379386675\n",
            "each epoch's objective value is0.21062697110042572\n",
            "each epoch's objective value is0.21060217472806086\n",
            "each epoch's objective value is0.21057950665761715\n",
            "each epoch's objective value is0.21056105177966522\n",
            "each epoch's objective value is0.21054264085915184\n",
            "each epoch's objective value is0.2105260424571213\n",
            "each epoch's objective value is0.2105112320631475\n",
            "each epoch's objective value is0.21049725569696254\n",
            "each epoch's objective value is0.21048596254577706\n",
            "each epoch's objective value is0.2104751092264605\n",
            "each epoch's objective value is0.2104651194790897\n",
            "each epoch's objective value is0.21045693449207872\n",
            "each epoch's objective value is0.21044888371261405\n",
            "each epoch's objective value is0.21044210142257755\n",
            "each epoch's objective value is0.210435443053034\n",
            "each epoch's objective value is0.21042970019468932\n",
            "each epoch's objective value is0.21042478200233902\n",
            "each epoch's objective value is0.21041994436133774\n",
            "each epoch's objective value is0.21041587603344483\n",
            "each epoch's objective value is0.21041213668920294\n",
            "each epoch's objective value is0.21040875099187792\n",
            "each epoch's objective value is0.21040566926935722\n",
            "each epoch's objective value is0.2104028740663241\n",
            "each epoch's objective value is0.21040049412687595\n",
            "each epoch's objective value is0.2103982368302915\n",
            "each epoch's objective value is0.21039625257998232\n",
            "each epoch's objective value is0.21039445204131196\n",
            "each epoch's objective value is0.2103928098430909\n",
            "each epoch's objective value is0.2103913516749831\n",
            "each epoch's objective value is0.2103900555910631\n",
            "each epoch's objective value is0.21038887007408547\n",
            "each epoch's objective value is0.21038780056994544\n",
            "each epoch's objective value is0.21038683794989363\n",
            "each epoch's objective value is0.21038597902510084\n",
            "each epoch's objective value is0.21038520092331545\n",
            "each epoch's objective value is0.21038449882795549\n",
            "each epoch's objective value is0.21038387253269392\n",
            "each epoch's objective value is0.21038330407135275\n",
            "each epoch's objective value is0.21038279510974617\n",
            "each epoch's objective value is0.2103823353735046\n",
            "each epoch's objective value is0.21038192363388028\n",
            "each epoch's objective value is0.2103815517974319\n",
            "each epoch's objective value is0.21038121712715255\n",
            "each epoch's objective value is0.21038091539564696\n",
            "each epoch's objective value is0.21038064437671572\n",
            "each epoch's objective value is0.21038040020690757\n",
            "each epoch's objective value is0.21038018030991715\n",
            "each epoch's objective value is0.21037998305351768\n",
            "each epoch's objective value is0.21037980532950007\n",
            "each epoch's objective value is0.21037964510972532\n",
            "each epoch's objective value is0.21037950111268097\n",
            "each epoch's objective value is0.210379371328135\n",
            "each epoch's objective value is0.21037925461622986\n",
            "each epoch's objective value is0.2103791495664513\n",
            "each epoch's objective value is0.21037905504967772\n",
            "each epoch's objective value is0.21037896996188107\n",
            "each epoch's objective value is0.21037889336568383\n",
            "each epoch's objective value is0.2103788244074999\n",
            "each epoch's objective value is0.21037876237963984\n",
            "each epoch's objective value is0.21037870656231997\n",
            "each epoch's objective value is0.210378656300285\n",
            "each epoch's objective value is0.21037861108095587\n",
            "each epoch's objective value is0.21037857037512653\n",
            "each epoch's objective value is0.21037853374930526\n",
            "each epoch's objective value is0.21037850077467937\n",
            "each epoch's objective value is0.21037847110659397\n",
            "each epoch's objective value is0.21037844440082318\n",
            "each epoch's objective value is0.21037842036685822\n",
            "each epoch's objective value is0.21037839873345004\n",
            "each epoch's objective value is0.2103783792651909\n",
            "each epoch's objective value is0.21037836174434957\n",
            "each epoch's objective value is0.210378345974215\n",
            "each epoch's objective value is0.21037833178202323\n",
            "each epoch's objective value is0.21037831900769194\n",
            "each epoch's objective value is0.21037830751256276\n",
            "each epoch's objective value is0.21037829716489437\n",
            "each epoch's objective value is0.21037828785245208\n",
            "each epoch's objective value is0.21037827947318208\n",
            "0.9736263736263736 0.9649122807017544\n"
          ]
        }
      ],
      "source": [
        "#for SGD, set the lam as 0.1 and learning_rate as 0.01\n",
        "w_optimal_r2,loss_r2=sgd(x_train,y_train,0.1,0.01, w=None)\n",
        "y_pred4 = predict(w_optimal_r2, x_train)\n",
        "acc4 = accuracy_score(y_train, y_pred4)\n",
        "y_pred4_test = predict(w_optimal_r2, x_test)\n",
        "acc4_test = accuracy_score(y_test, y_pred4_test)\n",
        "print(acc4,acc4_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AXn8xMv2z9q",
        "outputId": "496fea86-db13-4ce1-eaa7-71dd4e915549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "each epoch's objective value is[0.58557086]\n",
            "each epoch's objective value is[0.45184154]\n",
            "each epoch's objective value is[0.38960652]\n",
            "each epoch's objective value is[0.35367313]\n",
            "each epoch's objective value is[0.33034934]\n",
            "each epoch's objective value is[0.31406466]\n",
            "each epoch's objective value is[0.30211392]\n",
            "each epoch's objective value is[0.29302097]\n",
            "each epoch's objective value is[0.28591051]\n",
            "each epoch's objective value is[0.28023016]\n",
            "each epoch's objective value is[0.27561392]\n",
            "each epoch's objective value is[0.27180968]\n",
            "each epoch's objective value is[0.26863809]\n",
            "each epoch's objective value is[0.26596814]\n",
            "each epoch's objective value is[0.26370188]\n",
            "each epoch's objective value is[0.26176471]\n",
            "each epoch's objective value is[0.26009877]\n",
            "each epoch's objective value is[0.25865855]\n",
            "each epoch's objective value is[0.25740777]\n",
            "each epoch's objective value is[0.25631717]\n",
            "each epoch's objective value is[0.25536292]\n",
            "each epoch's objective value is[0.25452538]\n",
            "each epoch's objective value is[0.25378828]\n",
            "each epoch's objective value is[0.25313802]\n",
            "each epoch's objective value is[0.25256315]\n",
            "each epoch's objective value is[0.25205397]\n",
            "each epoch's objective value is[0.25160221]\n",
            "each epoch's objective value is[0.25120079]\n",
            "each epoch's objective value is[0.25084364]\n",
            "each epoch's objective value is[0.25052549]\n",
            "each epoch's objective value is[0.25024179]\n",
            "each epoch's objective value is[0.24998855]\n",
            "each epoch's objective value is[0.24976233]\n",
            "each epoch's objective value is[0.24956008]\n",
            "each epoch's objective value is[0.24937914]\n",
            "each epoch's objective value is[0.24921717]\n",
            "each epoch's objective value is[0.2490721]\n",
            "each epoch's objective value is[0.2489421]\n",
            "each epoch's objective value is[0.24882555]\n",
            "each epoch's objective value is[0.24872103]\n",
            "each epoch's objective value is[0.24862725]\n",
            "each epoch's objective value is[0.24854309]\n",
            "each epoch's objective value is[0.24846754]\n",
            "each epoch's objective value is[0.2483997]\n",
            "each epoch's objective value is[0.24833877]\n",
            "each epoch's objective value is[0.24828403]\n",
            "each epoch's objective value is[0.24823485]\n",
            "each epoch's objective value is[0.24819066]\n",
            "each epoch's objective value is[0.24815093]\n",
            "each epoch's objective value is[0.24811523]\n",
            "each epoch's objective value is[0.24808312]\n",
            "each epoch's objective value is[0.24805426]\n",
            "each epoch's objective value is[0.24802831]\n",
            "each epoch's objective value is[0.24800497]\n",
            "each epoch's objective value is[0.24798398]\n",
            "each epoch's objective value is[0.2479651]\n",
            "each epoch's objective value is[0.24794811]\n",
            "each epoch's objective value is[0.24793284]\n",
            "each epoch's objective value is[0.2479191]\n",
            "each epoch's objective value is[0.24790673]\n",
            "each epoch's objective value is[0.24789561]\n",
            "each epoch's objective value is[0.24788561]\n",
            "each epoch's objective value is[0.2478766]\n",
            "each epoch's objective value is[0.2478685]\n",
            "each epoch's objective value is[0.24786121]\n",
            "each epoch's objective value is[0.24785466]\n",
            "each epoch's objective value is[0.24784876]\n",
            "each epoch's objective value is[0.24784344]\n",
            "each epoch's objective value is[0.24783867]\n",
            "each epoch's objective value is[0.24783437]\n",
            "each epoch's objective value is[0.2478305]\n",
            "each epoch's objective value is[0.24782702]\n",
            "each epoch's objective value is[0.24782388]\n",
            "each epoch's objective value is[0.24782106]\n",
            "each epoch's objective value is[0.24781852]\n",
            "each epoch's objective value is[0.24781624]\n",
            "each epoch's objective value is[0.24781419]\n",
            "each epoch's objective value is[0.24781234]\n",
            "each epoch's objective value is[0.24781067]\n",
            "each epoch's objective value is[0.24780917]\n",
            "each epoch's objective value is[0.24780783]\n",
            "each epoch's objective value is[0.24780661]\n",
            "each epoch's objective value is[0.24780552]\n",
            "each epoch's objective value is[0.24780454]\n",
            "each epoch's objective value is[0.24780365]\n",
            "each epoch's objective value is[0.24780286]\n",
            "each epoch's objective value is[0.24780214]\n",
            "each epoch's objective value is[0.2478015]\n",
            "each epoch's objective value is[0.24780092]\n",
            "each epoch's objective value is[0.24780039]\n",
            "each epoch's objective value is[0.24779992]\n",
            "each epoch's objective value is[0.2477995]\n",
            "each epoch's objective value is[0.24779912]\n",
            "each epoch's objective value is[0.24779878]\n",
            "each epoch's objective value is[0.24779847]\n",
            "each epoch's objective value is[0.24779819]\n",
            "each epoch's objective value is[0.24779794]\n",
            "each epoch's objective value is[0.24779772]\n",
            "each epoch's objective value is[0.24779752]\n",
            "each epoch's objective value is[0.24779733]\n",
            "0.9538461538461539 0.9473684210526315\n"
          ]
        }
      ],
      "source": [
        "#for MBGD, set the lam as 0 and learning_rate as 0.01\n",
        "w_optimal_r2,loss_r2=mbgd(x_train,y_train,0.1,0.01, w=None)\n",
        "y_pred4 = predict(w_optimal_r2, x_train)\n",
        "acc4 = accuracy_score(y_train, y_pred4)\n",
        "y_pred4_test = predict(w_optimal_r2, x_test)\n",
        "acc4_test = accuracy_score(y_test, y_pred4_test)\n",
        "print(acc4,acc4_test) \n",
        "# accuracy = 0.5956043956043956"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Assignment 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}